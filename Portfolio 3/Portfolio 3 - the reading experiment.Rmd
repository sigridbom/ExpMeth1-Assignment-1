---
title: "Portfolio 3 - The Reading Experiment"
author: "Sigrid"
date: "11/7/2019"
output: html_document
---

First I load the relevant packages and import my data from the reading experiment and the data from the MRC database. I will use the MRC database in order to determine the frequency of the words used in the experiment according to normal English
. 
```{r setup, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse, pastecs, WRS2, stringr, stringi)

mrc_data <- read_csv("MRC_database.csv")

files <- list.files(path = "logfiles",     
                    pattern = ".csv",  
                    full.names = T) 
data <- lapply(files, read_csv) %>% plyr::rbind.fill()

#fixing gender with both upper and lower case due to a prior mistake in the code when conducting the experiment
data$Gender <- tolower(data$Gender)

```

#Part 1 - Which properties of words correlate with word-by-word reading times?

First I will investigate whether the data are normally distributed or not. If it is normally distributed I can calculate the correlation with parametric tests, and if not I will use non-parametric tests. 

```{r checking assumptions}

reac_hist <- ggplot(data, aes(Reaction_time))
reac_hist + geom_histogram(aes(y=..density..), binwidth = 0.8) + stat_function(fun = dnorm, args = list(mean(data$Reaction_time), sd = sd(data$Reaction_time)), colour = "red", size = 1) + theme_classic()

qq_plot <- ggplot(data, aes(sample = Reaction_time)) 
qq_plot + stat_qq() + stat_qq_line(colour = "red")

```

The histogram (where the red line shows what that would look like if it was normally distributed) is not looking normally distributed at all. The QQ-plot looks a little bit better. I'll now try to remove outliers and see if that helps the data follow the red line. 

```{r transforming the data - outliers}

data$z <- (data$Reaction_time - mean(data$Reaction_time))/sd(data$Reaction_time)

#filtering the dataframe

data_out <- filter(data, data$z <=3 | data$z <=-3)

#making a new histogram
reac_hist2 <- ggplot(data_out, aes(Reaction_time))
reac_hist2 + geom_histogram(aes(y=..density..), binwidth = 0.8) + stat_function(fun = dnorm, args = list(mean(data$Reaction_time), sd = sd(data$Reaction_time)), colour = "red", size = 1) + theme_classic()

#making a new qqplot
qq_plot2 <- ggplot(data_out, aes(sample = Reaction_time)) 
qq_plot2 + stat_qq() + stat_qq_line(colour = "red")
```

It helped, but the data are still not follwing the red line very well in both the histogram and the qq-plot. I'll new look at the numeric values for the data.

```{r}
round(pastecs::stat.desc(data$Reaction_time, basic = F, norm = TRUE), digits = 2)
```

The values of skew.2SE and kurt.2SE are extremely high, 72,80 and 467,70 respectively. 
The Shapiro-Wilk test has a value of 0,67 with a corresponding p-value of 0,00. This implies that the data are significantly different than a normal distrubtion.

The visual and the numeric outcome strongly indicates that the data are not normally distributed. 

I will therefore continue with non-parametric tests for correlation, i.e. Kendalls' Tau or Spearman's Rho. I will use Kendalls' Tau because our data set is fairly small, since we have less than 30 logfiles. 


```{r word length and correlation}
#maybe with outliers??????
#removing punctuation
data_out <- mutate(data_out, Stimulus = str_replace_all(data_out$Stimulus, "[:punct:]", ""))

#making a new column with the lenght of the word
data_out$word_len <- nchar(data_out$Stimulus)

#correlation test
cor.test(data_out$word_len, data_out$Reaction_time, method = "kendall")

```
A Kendall's Tau value of 1 indicates a perfect positive correlation, where a value of -1 indicates a perfect negative correlation. A value of 0 indicates no correlation. 

The correlation between word length and reading time is 0,07 which is close to 0. This strongly indicates that there is no correlation between the two variables. BUT THE P-VALUE IS SIGNIFICANT ?????????


```{r word frequency}

#with outliers??????
data_out$word <- toupper(data_out$Stimulus)

df_merge <- merge(data_out, mrc_data, by = "word")


cor.test(df_merge$kf_freq, df_merge$Reaction_time, method = "kendall")


```



```{r word number}

cor.test(data$X1, data$Reaction_time, method = "spearman")
#notice no outliers -- need all words
#eller kendall?????
```
#Part 2 - How do semantic-contextual expectations affect reading times?

To the fun part. 

```{r}

data_1 <- filter(data, data$Version == "stream.")

data_2 <- filter(data, data$Version == "building.")

data_1_2 <- filter(data_1, data_1$X1 == "107")

data_2_2 <- filter(data_2, data_2$X1 == "107")

data_con_1 <- filter(data, data$X1 == c(106, 107), data$Version == "stream.")
data_con_2 <- filter(data, data$X1 == c(106, 107), data$Version == "building.")

data_106 <- filter(data, data$X1 == 106)
data_107 <- filter(data, data$X1 == 107)

```


```{r t-test}

t.test(Reaction_time ~ Version, data = data_106)

t.test(Reaction_time ~ Version, data = data_107)

WRS2::yuen(Reaction_time ~ Version, data = data_106)

WRS2::yuen(Reaction_time ~ Version, data = data_107)

```

NOTES
Non-parametric test (not normally distributed) Kendalls Tau and Spearman's Rho
Covariance
#Fabio
Word frequency - mrc database

t.test
two seperate tests for each of the conditions (building and stream vs the following word from the two conditions). number something for "they"
keep it minimalistic

LÆS OM FORSKEL på kendall og spearman (ordinal variables? - see class 5 lecture slides)

