---
title: "Chapter 7 - Regression"
author: "Sigrid"
date: "11/5/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
getwd()
```

```{r library}
pacman::p_load(car, QuantPsyc, boot, tidyverse)
```

7.4.1 Doing simple regression using R --> 7.5.3

```{r SELF TEST 1+2}
album1 <- read.delim("Album Sales 1.dat")

album1_scat <- ggplot(album1, aes(adverts, sales)) 
album1_scat + geom_point() + geom_smooth(method = "lm") + theme_minimal()

#summary(lm(outcome ~ predictor, data = mydata))
albumSales.1 <-  lm(album1$sales ~ album1$adverts)
summary(albumSales.1)

#self-test
#t-test b_observed / SE_b
134.14/7.537 
= 17,79

#not the same as this though..
t.test(album1$sales, album1$adverts)

#self-test 2, the lastest album by Abgott
#albumsales = b_0 + b_1 x advertising budget
134.14+(0.096*666)
#answer 198.076 i.e. 198.076.000 ablums the first week!

```

7.8.2.2. Multiple regression using R

```{r}

album2 <- read.delim("Album Sales 2.dat")

albumSales.2 <- lm(sales ~ adverts, data = album2)

albumSales.3 <- lm(sales ~ adverts + airplay + attract, data = album2)
#update() function adds new predictors to an already existing regression function
# albumsales.3 <- update(albumSales.2, .~. + airplay + attract)

summary(albumSales.2)
summary(albumSales.3)

#standardized versions of the b-values
lm.beta(albumSales.3)

#measured in standard deviaton units, so comparable across models 

#getting the confidence intervals
confint(albumSales.3)

```

7.8.4.2. Comparing models

```{r}
anova(albumSales.2, albumSales.3)

```

Here the Pr(>F) is 2,2e-16 (a very small number indeed), we can therefore say:
The albumSales.3 significantly improved the fit of the model to the data compared to albumSales.2, F(2, 196) = 96,44, p < .001.

We are here looking at the change in R^2 from one model to the other model. 

by hand it would look like this:

F = (N-k-1)R^2 / k(1-R^2)
where N is the total amount of samples, k is the number of predictors and R^2 is the amount of variance explained by the model in decimal numbers. 

if we want the change between two models (the anova function)

F = (N-k_2 - 1)R^2_change / k_change(1-R^2_2)

where k_2 is the change in the number of predictors, R^2_change is the change between R^2 in the old model vs the new model and R^2_2 is R^2 in the new model. 

#7.9.3 Assessing the assumption of independence

```{r}
dwt(albumSales.3)

vif(albumSales.3)
1/vif(albumSales.3)
```

#Plots

```{r}
plot(albumSales.3)
hist(rstudent(albumSales.3))
```

#Smart Alex's Tasks 1

```{r Smart Alex's Task 1}
#simple regression - predict mortality from number of pubs

pubdata <- read.delim("pubs.dat")

pub_scat <- ggplot(pubdata, aes(pubs, mortality))
pub_scat + geom_point() + geom_smooth(method = "lm")

pubdata_predict <- lm(mortality ~ pubs, data = pubdata)
summary(pubdata_predict)

```

```{r Smart Alex's Task 2}

supermodeldata <- read.delim("Supermodel.dat")

#multiple regression
sup_re <- lm(salary ~ age + years + beauty, data = supermodeldata)
summary(sup_re)

#which variables predict the salaries of the models? how valid is the regression? 

lm.beta(sup_re)

confint(sup_re)
```
R^2 is 0,184 = 18,4 percent of the variance is explained by the model... 
age (b = 6,23) as the age increases by unit (probably one year), the salary increases by 6,23
years (b = -5,56) when the experience increases one unit the salary decreases by -5,56
beauty (b = -0,20) when the beauty of the model increases one percent the salary decreases by -0,2.
if the other predictors are held constant!!


```{r}

```

